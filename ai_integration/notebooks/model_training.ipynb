{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cda2d618",
   "metadata": {},
   "source": [
    "# Fuel-Efficient Route Model Training and Saving\n",
    "\n",
    "This notebook will:\n",
    "1. Load and preprocess vehicle and traffic data.\n",
    "2. Merge the datasets and prepare features/targets.\n",
    "3. Split the data, scale the features.\n",
    "4. Build and train two neural network models:\n",
    "   - Fuel Consumption Model\n",
    "   - CO₂ Emissions Model\n",
    "5. Save the trained models as `.h5` files in the `models/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a45c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d8fb68",
   "metadata": {},
   "source": [
    "## 1. Load Your Data\n",
    "\n",
    "We will load the following CSV files:\n",
    "- `data/vehicle data/vehicles.csv`\n",
    "- `data/traffic data/Traffic_Volumes.csv`\n",
    "- `data/traffic data/Bottlenecks.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data files\n",
    "vehicle_data1 = pd.read_csv('../data/vehicle data/CO2Emissions_Canada.csv')\n",
    "vehicle_data2 = pd.read_csv('../data/vehicle data/vehicles.csv')\n",
    "traffic_volumes = pd.read_csv('../data/traffic data/Traffic_Volumes_AADT.csv')\n",
    "bottlenecks = pd.read_csv('../data/traffic data/Bottlenecks.csv')\n",
    "\n",
    "print(\"Vehicle Data Samples:\")\n",
    "print(vehicle_data1.head())\n",
    "print(vehicle_data2.head())\n",
    "print(\"\\nTraffic Volumes Sample:\")\n",
    "print(traffic_volumes.head())\n",
    "print(\"\\nBottlenecks Sample:\")\n",
    "print(bottlenecks.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97ab0ee2",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "- Remove any missing values.\n",
    "- Rename columns in the vehicle data for clarity.\n",
    "- Compute a combined fuel efficiency as a weighted average.\n",
    "- Normalize the traffic severity in the bottlenecks data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values from all datasets\n",
    "vehicle_data1.dropna(inplace=True)\n",
    "vehicle_data2.dropna(inplace=True)\n",
    "traffic_volumes.dropna(inplace=True)\n",
    "bottlenecks.dropna(inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "vehicle_data1.rename(columns={\n",
    "    'Fuel Consumption City (L/100 km)': 'city_fuel_efficiency',\n",
    "    'Fuel Consumption Hwy (L/100 km)': 'highway_fuel_efficiency',\n",
    "    'CO2 Emissions(g/km)': 'co2_emissions'\n",
    "}, inplace=True)\n",
    "\n",
    "vehicle_data2.rename(columns={\n",
    "    'make': 'Make'\n",
    "}, inplace=True)\n",
    "\n",
    "traffic_volumes.rename(columns={\n",
    "    'COUNTY': 'County'\n",
    "}, inplace=True)\n",
    "\n",
    "vehicle_data = pd.merge(\n",
    "    vehicle_data1,\n",
    "    vehicle_data2,\n",
    "    on='Make',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Compute combined fuel efficiency (55% city, 45% highway)\n",
    "vehicle_data['combined_fuel_efficiency'] = (\n",
    "    vehicle_data['city_fuel_efficiency'] * 0.55 +\n",
    "    vehicle_data['highway_fuel_efficiency'] * 0.45\n",
    ")\n",
    "\n",
    "# Normalize traffic severity (0 to 1)\n",
    "bottlenecks['normalized_traffic_severity'] = (\n",
    "    bottlenecks['Total_Delay__veh_hrs_'] / bottlenecks['Total_Delay__veh_hrs_'].max()\n",
    ")\n",
    "\n",
    "print(\"Data cleaning and preprocessing complete.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c10cda8e",
   "metadata": {},
   "source": [
    "## 3. Merge Datasets\n",
    "\n",
    "- Merge the traffic volumes with the bottlenecks on 'County'.\n",
    "- Merge the resulting dataset with the vehicle data on 'fuelType'.\n",
    "- Compute the fuel consumption: In progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge traffic volumes with bottlenecks on 'County'\n",
    "traffic_data = pd.merge(\n",
    "    traffic_volumes,\n",
    "    bottlenecks[['County', 'normalized_traffic_severity']],\n",
    "    on='County',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(vehicle_data.columns)\n",
    "print(\"Traffic Data Sample:\")\n",
    "print(traffic_data.shape)\n",
    "print(traffic_data.head())\n",
    "\n",
    "'''\n",
    "traffic_summary = traffic_data.groupby('County').agg({\n",
    "    'normalized_traffic_severity': 'mean'\n",
    "}).reset_index()\n",
    "'''\n",
    "\n",
    "vehicle_summary = vehicle_data.groupby('fuelType').agg({\n",
    "    'combined_fuel_efficiency': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Traffic Summary Shape:\", traffic_summary.shape)\n",
    "print(\"Vehicle Summary Shape:\", vehicle_summary.shape)\n",
    "\n",
    "\n",
    "# Merge summarized data on 'County'\n",
    "merged_data = pd.merge(traffic_summary, vehicle_summary, how='cross')  # Cartesian merge (all traffic data with all vehicles)\n",
    "\n",
    "# Sample fuel consumption formula (proxy)\n",
    "merged_data['fuel_consumption'] = merged_data['normalized_traffic_severity'] / merged_data['combined_fuel_efficiency']\n",
    "\n",
    "print(\"Merged Data Sample:\")\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b9a1ee",
   "metadata": {},
   "source": [
    "## 4. Prepare Features and Targets\n",
    "\n",
    "- **Features (X):** distance, normalized_traffic_severity, combined_fuel_efficiency\n",
    "- **Targets:**\n",
    "  - y_fuel for fuel consumption prediction.\n",
    "  - y_co2 for CO₂ emissions prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variables\n",
    "X = merged_data[['distance', 'normalized_traffic_severity', 'combined_fuel_efficiency']]\n",
    "y_fuel = merged_data['fuel_consumption']\n",
    "y_co2 = merged_data['co2_emissions']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Fuel Consumption target shape:\", y_fuel.shape)\n",
    "print(\"CO₂ Emissions target shape:\", y_co2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc28b761",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split and Scaling\n",
    "\n",
    "- Split the data into training and testing sets.\n",
    "- Scale the features using StandardScaler for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea46952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for fuel consumption\n",
    "X_train, X_test, y_fuel_train, y_fuel_test = train_test_split(X, y_fuel, test_size=0.2, random_state=42)\n",
    "# Use the same split for CO₂ emissions target\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X, y_co2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for the fuel model\n",
    "scaler_fuel = StandardScaler()\n",
    "X_train_fuel = scaler_fuel.fit_transform(X_train)\n",
    "X_test_fuel = scaler_fuel.transform(X_test)\n",
    "\n",
    "# Scale features for the CO₂ model\n",
    "scaler_co2 = StandardScaler()\n",
    "X_train_co2 = scaler_co2.fit_transform(X_train)\n",
    "X_test_co2 = scaler_co2.transform(X_test)\n",
    "\n",
    "print(\"Train-Test split and scaling complete.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb7c1ca",
   "metadata": {},
   "source": [
    "## 6. Define a Model Builder Function\n",
    "\n",
    "This function creates a simple feedforward neural network for regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c183822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "print(\"Model builder function defined.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4457f896",
   "metadata": {},
   "source": [
    "## 7. Train the Models\n",
    "\n",
    "We train two models:\n",
    "- Fuel Consumption Model\n",
    "- CO₂ Emissions Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Fuel Consumption Model\n",
    "print(\"Training Fuel Consumption Model...\")\n",
    "model_fuel = build_model(X_train_fuel.shape[1])\n",
    "model_fuel.fit(X_train_fuel, y_fuel_train, validation_split=0.2, epochs=30, batch_size=32, verbose=1)\n",
    "\n",
    "# Train CO₂ Emissions Model\n",
    "print(\"\\nTraining CO₂ Emissions Model...\")\n",
    "model_co2 = build_model(X_train_co2.shape[1])\n",
    "model_co2.fit(X_train_co2, y_co2_train, validation_split=0.2, epochs=30, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27550826",
   "metadata": {},
   "source": [
    "## 8. Save the Trained Models\n",
    "\n",
    "The models will be saved as `.h5` files in the `models/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95597b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "model_fuel.save('models/fuel_consumption_model.h5')\n",
    "model_co2.save('models/co2_emissions_model.h5')\n",
    "\n",
    "print(\"Models saved in the 'models/' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
